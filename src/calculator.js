// src/calculator.js
const { performance } = require('perf_hooks');
const ss = require('simple-statistics');

/**
 * Generates an array of a specified size for testing algorithms.
 * @param {number} n The desired size of the array.
 * @returns {Array<number>} A new array of size 'n'.
 */
function generateInputArray(n) {
  return Array.from({ length: n }, (_, i) => i);
}

/**
 * Runs an algorithm with varying input sizes and collects execution times.
 * @param {Function} algorithm The function to test for Big O complexity.
 * @param {Array<number>} inputSizes An array of input sizes to test.
 * @param {number} iterations Number of times to run per input size (default 10).
 * @returns {Array<{n: number, time: number}>} An array of data points.
 */
function runAnalysis(algorithm, inputSizes, iterations = 10, inputMode = 'array') {
  const dataPoints = [];

  // Warmup phase: Run with the smallest input size a few times to trigger JIT
  if (inputSizes.length > 0) {
    const warmupSize = inputSizes[0];
    const warmupInput = inputMode === 'number' ? warmupSize : generateInputArray(warmupSize);
    // Increased warmup iterations to ensure JIT optimization
    for (let i = 0; i < 100; i++) {
      algorithm(warmupInput);
    }
  }

  for (const n of inputSizes) {
    // Adaptive Batching Calibration
    // Determine how many iterations (batchSize) are needed to get a measurable execution time (~10ms)
    // This is crucial for very fast algorithms (O(1), O(log n)) to avoid system timer noise.
    let batchSize = 1;
    const calibrationInput = inputMode === 'number' ? n : generateInputArray(n);
    let calStart = performance.now();
    let calEnd = calStart;
    let calCount = 0;

    // Run until at least 5ms have passed or we hit a safety limit
    // We increment calCount to avoid infinite loops if the clock doesn't advance
    while ((calEnd - calStart) < 5 && calCount < 1000000) {
      // Execute the algorithm
      // Note: We reuse the input. This assumes the algorithm is read-only or idempotent.
      // For O(1)/O(log n) detection, this is usually true and necessary for accuracy.
      algorithm(calibrationInput);
      calCount++;
      calEnd = performance.now();
    }

    const calDuration = calEnd - calStart;
    if (calCount > 1) {
      // If we needed multiple runs to reach 5ms, we calculate a batchSize for ~15ms per measurement
      // batchSize = (Target Time / Time per Op) = (15 / (calDuration / calCount))
      //             = (15 * calCount) / calDuration
      batchSize = Math.ceil((15 * calCount) / (calDuration || 0.001));
    }

    const times = [];
    for (let i = 0; i < iterations; i++) {
      // Generate the correct input type for each iteration
      const inputForAlgorithm = inputMode === 'number' ? n : generateInputArray(n);

      const start = performance.now();
      // Execute batch
      for (let b = 0; b < batchSize; b++) {
        algorithm(inputForAlgorithm);
      }
      const end = performance.now();

      // Calculate average time per single execution
      times.push((end - start) / batchSize);
    }

    const avgTime = ss.mean(times);
    // or use median to remove outliers: const avgTime = ss.median(times); 

    dataPoints.push({ n, time: avgTime });
  }

  return dataPoints;
}

/**
 * Calculates the Root Mean Square Error (RMSE) between actual and predicted values.
 * @param {Array<number>} actual
 * @param {Array<number>} predicted
 * @returns {number}
 */
function calculateRMSE(actual, predicted) {
  const sumSquaredErrors = actual.reduce((sum, val, i) => sum + (val - predicted[i]) ** 2, 0);
  return Math.sqrt(sumSquaredErrors / actual.length);
}

/**
 * Determines the Big O complexity based on the RMSE of various regression models.
 * @param {Array<{n: number, time: number}>} dataPoints
 * @returns {Object} Analysis result with RMSE scores and best fit.
 */
function determineComplexity(dataPoints) {
  const nValues = dataPoints.map(d => d.n);
  const timeValues = dataPoints.map(d => d.time);

  // 1. O(1) Constant: Time = mean(Time)
  const meanTime = ss.mean(timeValues);
  const constantPredictions = nValues.map(() => meanTime);
  const constantRMSE = calculateRMSE(timeValues, constantPredictions);

  // Helper to run linear regression on transformed data and get RMSE
  const getRegressionRMSE = (transformFn) => {
    const data = dataPoints.map(d => [transformFn(d.n), d.time]);
    const model = ss.linearRegression(data);
    const line = ss.linearRegressionLine(model);
    const predictions = dataPoints.map(d => line(transformFn(d.n)));
    return calculateRMSE(timeValues, predictions);
  };

  // 2. O(n) Linear
  const linearRMSE = getRegressionRMSE(n => n);

  // 3. O(n^2) Quadratic
  const quadraticRMSE = getRegressionRMSE(n => n ** 2);

  // 4. O(log n) Logarithmic
  const logRMSE = getRegressionRMSE(n => Math.log(n));

  // 5. O(n log n) Linear-ithmic
  const nLogNRMSE = getRegressionRMSE(n => n * Math.log(n));

  const models = [
    { type: 'O(1) - Constant', rmse: constantRMSE, complexity: 1 },
    { type: 'O(log n) - Logarithmic', rmse: logRMSE, complexity: 2 },
    { type: 'O(n) - Linear', rmse: linearRMSE, complexity: 3 },
    { type: 'O(n log n) - Linear-ithmic', rmse: nLogNRMSE, complexity: 4 },
    { type: 'O(n^2) - Quadratic', rmse: quadraticRMSE, complexity: 5 }
  ];

  models.sort((a, b) => a.rmse - b.rmse);

  let bestModel = models[0];
  let confidence;

  // Hybrid approach: use a special heuristic for ultra-fast functions, and standard logic for others.
  const isUltraFast = meanTime < 1e-4;

  if (isUltraFast) {
    const o1Model = models.find(m => m.type.includes('O(1)'));
    const logModel = models.find(m => m.type.includes('O(log n)'));

    // For ultra-fast functions, trust the model with the mathematically superior (lower) RMSE.
    if (logModel && o1Model && logModel.rmse < o1Model.rmse) {
      bestModel = logModel;
    } else {
      bestModel = o1Model; // Default to O(1) otherwise
    }
    
    confidence = 95; // Assign a high, fixed confidence score based on this heuristic.
  } else {
    // Standard logic for macroscopic measurements: prefer simpler models if they are "close enough".
    for (let i = 1; i < models.length; i++) {
      const candidate = models[i];
      if (candidate.complexity < bestModel.complexity) {
        const diff = (candidate.rmse - bestModel.rmse) / (bestModel.rmse || 1e-9);
        if (diff < 0.15) { // 15% tolerance
          bestModel = candidate;
        }
      }
    }

    // Standard confidence calculation for slower functions
    const signalMagnitude = meanTime > 0 ? meanTime : 1;
    const normalizedError = bestModel.rmse / signalMagnitude;
    const fitQuality = Math.max(0, 1 - (normalizedError * 2));

    const sortedByFit = [...models].sort((a, b) => a.rmse - b.rmse);
    let secondBest = sortedByFit[0];
    if (secondBest === bestModel) {
      secondBest = sortedByFit[1];
    }

    let separation = 0;
    if (secondBest) {
      separation = (secondBest.rmse - bestModel.rmse) / (secondBest.rmse || 1);
      separation = Math.min(1, separation);
    }

    confidence = (fitQuality * 0.7 + separation * 0.3) * 100;
  }

  // Formatting for output (converting RMSE to 4 decimals string if needed, or keeping number)
  const results = models.map(m => ({
    type: m.type,
    rmse: m.rmse
  }));

  // Re-sort results by RMSE for display purposes
  results.sort((a, b) => a.rmse - b.rmse);

  return {
    bestFit: bestModel.type,
    confidence: Math.round(confidence),
    results: results
  };
}

module.exports = {
  generateInputArray,
  runAnalysis,
  determineComplexity
};
